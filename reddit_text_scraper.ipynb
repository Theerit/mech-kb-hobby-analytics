{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de90dce-e2b6-4282-9a9c-22ede7d36ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from https://github.com/parth647/reddit_scraping_using_praw/blob/master/python_reddit_scrapy.py\n",
    "# Code from https://github.com/D3vd/Reddit_Image_Scraper/blob/master/Reddit_image_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1db14-156b-40eb-b37b-8de8a4234294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import praw\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import configparser\n",
    "from prawcore.exceptions import ResponseException\n",
    "\n",
    "from reddit_image_scrapper import get_img_subreddit, delete_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf536bb-ba8f-4c12-89f8-f41104b8d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_client_info():\n",
    "  config = configparser.ConfigParser()\n",
    "  config.read(\"config.ini\")\n",
    "  id = config[\"ALPHA\"][\"client_id\"]\n",
    "  secret = config[\"ALPHA\"][\"client_secret\"]\n",
    "\n",
    "  return id, secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e3c96-f3bb-4580-81b9-1b5ad3b99f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessing the reddit api\n",
    "\n",
    "clien_id, client_secret = get_client_info()\n",
    "reddit = praw.Reddit(client_id=clien_id,#my client id\n",
    "                     client_secret=client_secret,  #your client secret\n",
    "                     user_agent='retrieve kb data', #user agent name\n",
    "                     username = '',     # your reddit username\n",
    "                     password = '')     # your reddit password\n",
    "\n",
    "sub = ['MechanicalKeyboards']  # make a list of subreddits you want to scrape the data from\n",
    "# Alternate sub to mine: 'MechanicalKeyboards'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf73bcc-106e-4b8b-afa8-a9f85072ecd1",
   "metadata": {},
   "source": [
    "## To scrape stickied comments and pictures of the reddit post\n",
    "main file -> json with the following format\n",
    "{'sticky_comment': raw_text, 'title': raw_text, 'img_path': [path_to_saved_images]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e775963-5d35-41ce-ac4a-2179135cc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_scraped_dict = []\n",
    "\n",
    "delete_img_list() # Delete image list to get clean slate\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "try:\n",
    "  for i, submission in enumerate(reddit.subreddit('MechGroupBuys').new(limit=2000)):    \n",
    "    \n",
    "    title_pattern = '\\[(?:GB|Pre-order|Preorder|In-stock)\\](.*)/' #Bring text eda code to help save files\n",
    "    try:\n",
    "      title = re.findall(title_pattern, submission.title.replace('\\n', ''))[0].replace('/', '').strip()\n",
    "    except:\n",
    "      title = submission.title.replace('[GB]', '').strip()\n",
    "      title = title[:title.find('//')]\n",
    "  \n",
    "    \n",
    "    if os.path.exists(os.path.join('data', f'scrapped_data_{title}.json')): continue\n",
    "    print(submission.title)\n",
    "    for top_level_comment in submission.comments:\n",
    "      if top_level_comment.stickied:        \n",
    "        \n",
    "        # If the key is to extract the price, try to parse all rows into text file then manipulate from there\n",
    "        #print(top_level_comment.body)\n",
    "        sticky_comment = top_level_comment.body\n",
    "        \n",
    "    list_file_loc = get_img_subreddit(submission, num_img_limit=50, sleep_interval=1)\n",
    "    scraped_dict = {'title': submission.title, 'sticky_comment': sticky_comment, 'img_paths': list_file_loc}\n",
    "            \n",
    "    with open(os.path.join('data', f'scrapped_data_{title}.json'), 'w') as json_output:\n",
    "      json.dump(scraped_dict, json_output, indent=2)\n",
    "\n",
    "    #list_scraped_dict.append(scraped_dict)\n",
    "      \n",
    "  #with open(\"scrapped_data.json\", \"w\") as json_output:\n",
    "   #json.dump(list_scraped_dict, json_output, indent=2)\n",
    "  \n",
    "          \n",
    "except ResponseException as e:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e48de-3029-4c18-9756-3652e1bf4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#   #for submission in reddit.subreddit(\"MechanicalKeyboards\").new(limit=10):\n",
    "#   submissions = reddit.subreddit(\"MechGroupBuys\").new(limit=10)\n",
    "#   #for submission in submissions: print(submission.url)\n",
    "\n",
    "#   # The important thing is the code now works\n",
    "#   get_img_subreddit(submission, num_img_limit=50, sleep_interval=3)\n",
    "\n",
    "# except ResponseException as e:\n",
    "#   pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f48105-077c-4092-a4d8-ca1f7141fcd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Code below this cell is not in use for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a8e2c-a8e7-4f19-b007-d1252f2262d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "########################################\n",
    "#   CREATING DICTIONARY TO STORE THE DATA WHICH WILL BE CONVERTED TO A DATAFRAME\n",
    "########################################\n",
    "\n",
    "#   NOTE: ALL THE POST DATA AND COMMENT DATA WILL BE SAVED IN TWO DIFFERENT\n",
    "#   DATASETS AND LATER CAN BE MAPPED USING IDS OF POSTS/COMMENTS AS WE WILL \n",
    "#   BE CAPTURING ALL IDS THAT COME IN OUR WAY\n",
    "\n",
    "# SCRAPING CAN BE DONE VIA VARIOUS STRATEGIES {HOT,TOP,etc} we will go with keyword strategy i.e using search a keyword\n",
    "# query = ['Gaming']\n",
    "\n",
    "# for item in query:\n",
    "#     post_dict = {\n",
    "#         \"title\" : [],\n",
    "#         \"score\" : [],\n",
    "#         \"id\" : [],\n",
    "#         \"url\" : [],\n",
    "#         \"comms_num\": [],\n",
    "#         \"created\" : [],\n",
    "#         \"body\" : []\n",
    "#     }\n",
    "#     comments_dict = {\n",
    "#         \"comment_id\" : [],\n",
    "#         \"comment_parent_id\" : [],\n",
    "#         \"comment_body\" : [],\n",
    "#         \"comment_link_id\" : []\n",
    "#     }\n",
    "#     for submission in subreddit.search(query,sort = \"top\",limit = 1):\n",
    "#         post_dict[\"title\"].append(submission.title)\n",
    "#         post_dict[\"score\"].append(submission.score)\n",
    "#         post_dict[\"id\"].append(submission.id)\n",
    "#         post_dict[\"url\"].append(submission.url)\n",
    "#         post_dict[\"comms_num\"].append(submission.num_comments)\n",
    "#         post_dict[\"created\"].append(submission.created)\n",
    "#         post_dict[\"body\"].append(submission.selftext)\n",
    "\n",
    "#         ##### Acessing comments on the post\n",
    "#         submission.comments.replace_more(limit = 1)\n",
    "#         for comment in submission.comments.list():\n",
    "#             comments_dict[\"comment_id\"].append(comment.id)\n",
    "#             comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "#             comments_dict[\"comment_body\"].append(comment.body)\n",
    "#             comments_dict[\"comment_link_id\"].append(comment.link_id)\n",
    "\n",
    "#     post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "#     post_comments.to_csv(s+\"_comments_\"+ item +\"subreddit.csv\")\n",
    "#     post_data = pd.DataFrame(post_dict)\n",
    "#     post_data.to_csv(s+\"_\"+ item +\"subreddit.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

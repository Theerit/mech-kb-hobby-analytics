{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1648570-dca7-4ad5-93a6-7bbcfd56ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b6ff5-8c4a-40a0-bf56-7e7e9061d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(start_date, end_date):\n",
    "  \"\"\"Create helper function to use for starting, ending date of group buy\n",
    "      Case1: has month day, year in the string\n",
    "      Case2: Has only month and day -> has to infer from the other dates\n",
    "      Case3: Sold out      \n",
    "  \"\"\"\n",
    "  \n",
    "  ymd_pattern = '(\\D*)\\s*(\\d{1,2})\\s*(?:rd|th|st|nd)*\\,*\\s*(\\d{4})*'\n",
    "  \n",
    "  start_tup = re.search(ymd_pattern, start_date)\n",
    "  start_m, start_d, start_y = start_tup.group(1), start_tup.group(2), start_tup.group(3)\n",
    "  \n",
    "  end_y = None\n",
    "  end_d = None\n",
    "  end_m = None\n",
    "  \n",
    "  if end_date != 'sold out': \n",
    "    end_tup = re.search(ymd_pattern, end_date)\n",
    "    \n",
    "    if end_tup is not None: \n",
    "      end_m, end_d, end_y = end_tup.group(1), end_tup.group(2), end_tup.group(3)    \n",
    "    if end_y is None and start_y is not None: end_y = start_y\n",
    "  \n",
    "  if start_y is None and end_y is not None: start_y = end_y  \n",
    "  out_start_date = dt.datetime.strptime(f\"{start_d.strip()}-{start_m.strip()}-{start_y.strip()}\", '%d-%B-%Y')\n",
    "  \n",
    "  #print(end_d, end_m, end_y)\n",
    "  \n",
    "  if end_date == 'sold out': \n",
    "    out_end_date = end_date\n",
    "  elif end_d is None or end_d == '' or end_m is None or end_m == '':\n",
    "    out_end_date = 'sold out'\n",
    "  else:\n",
    "    out_end_date = dt.datetime.strptime(f\"{end_d.strip()}-{end_m.strip()}-{end_y.strip()}\", '%d-%B-%Y')\n",
    "  \n",
    "  return out_start_date, out_end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c8a60-d24b-4a5a-95b7-acdcb7888506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_price(price, mode='mid'):\n",
    "  \"\"\"Helper Function used to process price column in case of varying price, e.g.: 30-55\n",
    "      mode = 'mid': calculate the mid price\n",
    "      mode = 'min': get the lower bound price\n",
    "      mode = 'max': get the upper bound price\n",
    "  \"\"\"\n",
    "  \n",
    "  print(price)\n",
    "  try:\n",
    "    price = price.replace('---', '') # Hack for some case\n",
    "    output_price = float(price)    \n",
    "  except:\n",
    "    low_price = float(price[:price.find('-')])\n",
    "    high_price = float(price[price.find('-'):])\n",
    "    if mode =='mid': \n",
    "      output_price = (low_price + high_price) * 0.5\n",
    "    elif mode == 'min':\n",
    "      output_price = low_price\n",
    "    elif mode == 'max':\n",
    "      output_price = high_price\n",
    "      \n",
    "  return output_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625b4b8-ef32-4be2-b216-54646541c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = []\n",
    "title_screen = []\n",
    "for file in os.listdir('data'):\n",
    "  #scraped_data = json.load(open(\"scrapped_data.json\", \"r\"))\n",
    "  if file.endswith('.json'):\n",
    "    scrp = json.load(open(os.path.join('data', file), 'r'))\n",
    "    scraped_data.append(scrp)\n",
    "    title_screen.append(scrp['title'])\n",
    "len(set(title_screen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7596b-a369-46f3-834d-35ab3dd50ae3",
   "metadata": {},
   "source": [
    "### Contruct the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d8ec7-6d6f-4950-942a-084482db4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a separate cell for the shipping date\n",
    "\n",
    "#ship_date_pattern = '(?:est\\.\\s*shipping\\s*date|est.\\s*fulfillment\\s*date):\\s*\\*\\*(.*?)\\*\\*---'\n",
    "#ship_date_pattern = '(?:.*?):\\s*\\*\\*(.*?)\\*\\*---'\n",
    "# ship_date_pattern = \\\n",
    "# \"\"\"(?:est\\.?\\s*shipping\\s*date|est.\\s*fulfillment\\s*date|est\\.?\\s*delivery\\s*date|est\\.?\\s*delivering\\s*date|estimated\\s*\\ship)\n",
    "# (?:from\\s*\\w*\\s*)?:\\s*\\*\\*(.*?)\\*\\*---\"\"\"\n",
    "\n",
    "\n",
    "# There's probably better method for this, like using word stemming\n",
    "ship_date_pattern = re.compile((\n",
    "  '(?:'\n",
    "    '(?:'\n",
    "      '(?:est|estimated|est.|estimate)\\s*'\n",
    "      '|'\n",
    "      '(?:eta)\\s*'\n",
    "    ')'\n",
    "    '(?:delivery|delivering|ship|shiping|shipping|fulfilment|fulfillment)?\\s*'\n",
    "    '(?:date)?\\s*'\n",
    "    '(?:from\\s*\\w*\\s*)?'\n",
    "  '):\\s*\\*?\\*?(.*?)\\*?\\*?---'\n",
    "))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf598fa-9c78-484e-8ce9-0879b9bcf792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#price_pattern = '(?:(price|prices):)(\\w*):\\s*\\*\\*\\s*\\$?(\\d*\\-*\\d*)\\*\\*'\n",
    "#price_pattern = '(?:\\*\\*(?:price:|prices:)?\\*\\*)?\\s*((\\w*\\s*):\\s*\\*\\*\\s*\\$?(\\d*\\-*\\d*)\\*\\*)'\n",
    "price_pattern = '(?:\\*\\*(?:price:|prices:)?\\*\\*)?\\s*(([^:]*):\\s*\\*\\*\\s*\\$?(\\d*\\-*\\d*)\\*\\*)'\n",
    "title_pattern = '\\[(?:GB|Pre-order)\\]\\s*(.*)\\s*//' #Trying not to lower case to preserve some kb title that has uppercase\n",
    "date_pattern = '//(.*)-(.*)'\n",
    "vendor_pattern = '(\\w*:\\s*)\\[(\\w*)\\]'\n",
    "\n",
    "type_list = []\n",
    "price_list = []\n",
    "title_list = []\n",
    "start_list = []\n",
    "end_list = []\n",
    "country_list = []\n",
    "vendor_list = []\n",
    "ship_date_list = []\n",
    "sticky_comment_list = [] #Does not really need if the code is super stable\n",
    "\n",
    "for scrp in scraped_data:\n",
    "  price_tup = re.findall(price_pattern, scrp['sticky_comment'].replace('\\n', '').lower())\n",
    "  try:\n",
    "    title = re.findall(title_pattern, scrp['title'].replace('\\n', ''))[0] #Title should match only 1 string  \n",
    "  except:\n",
    "    title = scrp['title'].replace('[GB]', '').strip()\n",
    "  try:\n",
    "    ship_date = re.findall(ship_date_pattern, scrp['sticky_comment'].replace('\\n', '').lower())[0]\n",
    "  except:\n",
    "    ship_date = None\n",
    "      \n",
    "  # first index is for tuple, second index is for the starting/ending date\n",
    "  try:\n",
    "    start_date = re.findall(date_pattern, scrp['title'].replace('\\n', ''))[0][0].strip().lower()\n",
    "    end_date = re.findall(date_pattern, scrp['title'].replace('\\n', ''))[0][1].strip().lower()\n",
    "    start_date, end_date = process_date(start_date, end_date)\n",
    "  except:\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "  \n",
    "  vendor_tup = re.findall(vendor_pattern, scrp['sticky_comment'].replace('\\n', ''))\n",
    "  \n",
    "  #print(len(price_tup), len(vendor_tup))\n",
    "  if len(price_tup) == 0: print(title)\n",
    "  for p_tup in price_tup: \n",
    "    for v_tup in vendor_tup:      \n",
    "      \n",
    "      type_list.append(p_tup[1]) #group 1 and group 2 of the match groups\n",
    "      price_list.append(p_tup[2])\n",
    "      \n",
    "      country_list.append(v_tup[0].replace(':', ''))\n",
    "      vendor_list.append(v_tup[1])\n",
    "\n",
    "      # These 4, 5 need to be duplicated across price/country\n",
    "      title_list.append(title)\n",
    "      start_list.append(start_date)\n",
    "      end_list.append(end_date)\n",
    "      ship_date_list.append(ship_date)\n",
    "      sticky_comment_list.append(scrp['sticky_comment'].replace('\\n', ''))\n",
    "\n",
    "df = pd.DataFrame({'title': title_list, 'type': type_list, 'price': price_list, 'start_date': start_list, 'end_date':end_list,\n",
    "                   'country': country_list, 'vendor': vendor_list, 'ship_date': ship_date_list, 'sticky_comment': sticky_comment_list\n",
    "                  })\n",
    "#df['price'] = df['price'].apply(lambda x: process_price(x, mode='mid'))\n",
    "#df\n",
    "df[df['price']=='']\n",
    "df['title'].value_counts()\n",
    "#print(df[df['ship_date'].isna()]['sticky_comment'].count())\n",
    "#df[df['ship_date'].isna()]['sticky_comment'].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06ca7d-4e2c-43d7-9afb-d718173178b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e36341-2b92-4eb0-926d-93b7084dff73",
   "metadata": {},
   "source": [
    "### Try to Extract the type (Keyboard vs Keycap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b110b-58aa-4531-b39c-91600f025b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_mech_product(row):\n",
    "  \"\"\"Drop duplicates by title and then pass in row of the dataframe for the separation\"\"\"\n",
    "  # Need heuristic to separate (unless use some model to separate pictures)    \n",
    "\n",
    "  # Let the rest falls down to keybaord, the hard part would be to differentiate keybard and switch\n",
    "  # Switch may be look from linear/tactile in the description or something, as well as look at the title\n",
    "  \n",
    "  # keycap title may contains GMK, ePBT, MW, Domikey, DCS, SA\n",
    "  for keycap_brand in ['gmk', 'epbt', 'mw', 'domikey', 'dcs', 'sa', 'osume']:\n",
    "    if keycap_brand in row['title'].lower():      \n",
    "      return 'keycap'\n",
    "  \n",
    "  # keycap type may include Alphas, Numpad, Spacebars, keycap\n",
    "  for type_kb in row['agg_type']: \n",
    "    if 'alphas' in type_kb.lower() or 'numpad' in type_kb.lower() or 'spacebar' in type_kb.lower() or 'artisan' in type_kb.lower() \\\n",
    "    or 'num' in type_kb.lower():\n",
    "      return 'keycap'\n",
    "  \n",
    "  # If is keyboard should have at least pcb or plate option\n",
    "  for type_kb in row['agg_type']: \n",
    "    if 'pcb' in type_kb.lower() or 'plate' in type_kb.lower() or 'fr4' in type_kb.lower():\n",
    "      return 'keyboard'\n",
    "    \n",
    "  # Check for 6x, 7x, 8x, tkl, 9x, 4x in name to flag for the keyboard\n",
    "  kb_sizes = [str(i) for i in range(60, 90)] + [str(i) for i in range(40, 50)] + ['tkl']\n",
    "  for kb_size in kb_sizes:\n",
    "    if kb_size in row['title'].lower():      \n",
    "      return 'keyboard'\n",
    "    \n",
    "  # Check for keyboard in title\n",
    "  if 'keyboard' in row['title'].lower():\n",
    "    return 'keyboard'\n",
    "  \n",
    "  # Check for deskmat in title\n",
    "  if 'deskmat' in row['title'].lower() or 'desk mat' in row['title'].lower():    \n",
    "    return 'deskmat'\n",
    "  \n",
    "  # Check for keycap in title\n",
    "  if 'keycap' in row['title'].lower() or 'key cap' in row['title'].lower():    \n",
    "    return 'deskmat'\n",
    "  \n",
    "  # If has switch in the type list should be switch\n",
    "  for type_kb in row['agg_type']:\n",
    "    if 'switch' in type_kb.lower():      \n",
    "      return 'switch'\n",
    "  \n",
    "  # If pass everything, flag as keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51522932-1a5a-4152-89f2-444897ca31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to combine the type for the\n",
    "df['agg_type'] = df.groupby('title')['type'].transform(lambda x: [x.tolist()]*len(x))\n",
    "# type count will be useful to see if there is only one mode of buying\n",
    "df['agg_type_count'] = df.groupby('title')['type'].transform(lambda x: [set(x.tolist())]*len(x))\n",
    "df_prod = df.drop_duplicates(['title']).copy()\n",
    "\n",
    "# Get the product type and join back\n",
    "df_prod['product'] = df_prod.apply(lambda x: sep_mech_product(x), axis=1)\n",
    "df_prod = df_prod[['title', 'product']].copy()\n",
    "df_prod['title'] = df_prod['title'].astype(str)\n",
    "df['title'] = df['title'].astype(str)\n",
    "df = df.merge(df_prod, on=['title'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98a06a4-bb13-468d-b7bb-6797f239c6d6",
   "metadata": {},
   "source": [
    "### Get Sum of All Price (per title per distributor), \n",
    "also get base minimal price to buy (check for 'base' or 'it' keyword or so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b125e-8470-4b89-8c69-d029212085d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_base_price(type_kb):\n",
    "  for base_type in ['base', 'kit', 'alpha', 'alphas']:\n",
    "    if type_kb.lower() == base_type: return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34146f76-f27c-4c79-96d6-0cebaf61159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sum of the price per title per studio per country\n",
    "df['sum_all_price'] = df.groupby(['title', 'vendor', 'country'])['price'].transform('sum')\n",
    "\n",
    "# get base/kit price\n",
    "df_base = df.loc[df['type'].apply(lambda x: check_base_price(x)), :].copy()\n",
    "df_base = df_base[['title', 'price']].copy().rename(columns={'price': 'base_price'})\n",
    "df = df.merge(df_base, on=['title'], how='left')\n",
    "\n",
    "# In case there is only one mode of buying, count that as base price\n",
    "df.loc[df['agg_type_count']==1, 'base_price'] = df.loc[df['agg_type_count']==1, 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7dce1-a0e8-4284-a024-2414e2b095a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['base_price'].isna()]\n",
    "df[df['title'].str.contains('GMK Olivia')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd4bb1a-88c2-4d35-8a9d-c8d760f54784",
   "metadata": {},
   "source": [
    "### Distribution of price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8d692-0d45-4816-bcc5-c0ca989d023a",
   "metadata": {},
   "source": [
    "### Distribution of Keyboard Type "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adf390-4547-446b-9fa8-44f106953d42",
   "metadata": {},
   "source": [
    "### Distribution of the Studio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077b324-1425-4789-ac8e-ca00bdc5594f",
   "metadata": {},
   "source": [
    "### Visualization of number of active group buy in a Year (maybe a stack chart of avaialble group buys/ price need to buy everything, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b065a3-6002-4858-9cab-e6ab4625f320",
   "metadata": {},
   "source": [
    "### Time from Group Buy to Release (as per the initial announcement data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d2612-e8b0-449b-98de-10b2bf509ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

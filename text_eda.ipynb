{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1648570-dca7-4ad5-93a6-7bbcfd56ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b6ff5-8c4a-40a0-bf56-7e7e9061d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date(start_date, end_date):\n",
    "  \"\"\"Create helper function to use for starting, ending date of group buy\n",
    "      Case1: has month day, year in the string\n",
    "      Case2: Has only month and day -> has to infer from the other dates\n",
    "      Case3: Sold out      \n",
    "  \"\"\"\n",
    "  \n",
    "  ymd_pattern = '(\\D*)\\s*(\\d{1,2})\\s*(?:rd|th|st|nd)*\\,*\\s*(\\d{4})*'\n",
    "  \n",
    "  start_tup = re.search(ymd_pattern, start_date)\n",
    "  start_m, start_d, start_y = start_tup.group(1), start_tup.group(2), start_tup.group(3)\n",
    "  \n",
    "  end_y = None\n",
    "  end_d = None\n",
    "  end_m = None\n",
    "  \n",
    "  if end_date != 'sold out': \n",
    "    end_tup = re.search(ymd_pattern, end_date)\n",
    "    \n",
    "    if end_tup is not None: \n",
    "      end_m, end_d, end_y = end_tup.group(1), end_tup.group(2), end_tup.group(3)    \n",
    "    if end_y is None and start_y is not None: end_y = start_y\n",
    "  \n",
    "  if start_y is None and end_y is not None: start_y = end_y  \n",
    "  out_start_date = dt.datetime.strptime(f\"{start_d.strip()}-{start_m.strip()}-{start_y.strip()}\", '%d-%B-%Y')\n",
    "  \n",
    "  #print(end_d, end_m, end_y)\n",
    "  \n",
    "  if end_date == 'sold out': \n",
    "    out_end_date = end_date\n",
    "  elif end_d is None or end_d == '' or end_m is None or end_m == '':\n",
    "    out_end_date = 'sold out'\n",
    "  else:\n",
    "    out_end_date = dt.datetime.strptime(f\"{end_d.strip()}-{end_m.strip()}-{end_y.strip()}\", '%d-%B-%Y')\n",
    "  \n",
    "  return out_start_date, out_end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9c8a60-d24b-4a5a-95b7-acdcb7888506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_price(price, mode='mid'):\n",
    "  \"\"\"Helper Function used to process price column in case of varying price, e.g.: 30-55\n",
    "      mode = 'mid': calculate the mid price\n",
    "      mode = 'min': get the lower bound price\n",
    "      mode = 'max': get the upper bound price\n",
    "  \"\"\"\n",
    "   \n",
    "  try:\n",
    "    output_price = float(price)\n",
    "  except:\n",
    "    low_price = float(price[:price.find('-')])\n",
    "    high_price = float(price[price.find('-'):])\n",
    "    if mode =='mid': \n",
    "      output_price = (low_price + high_price) * 0.5\n",
    "    elif mode == 'min':\n",
    "      output_price = low_price\n",
    "    elif mode == 'max':\n",
    "      output_price = high_price\n",
    "      \n",
    "  return output_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625b4b8-ef32-4be2-b216-54646541c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = []\n",
    "for file in os.listdir('data'):\n",
    "  #scraped_data = json.load(open(\"scrapped_data.json\", \"r\"))\n",
    "  if file.endswith('.json'):\n",
    "    scrp = json.load(open(os.path.join('data', file), 'r'))\n",
    "    scraped_data.append(scrp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7596b-a369-46f3-834d-35ab3dd50ae3",
   "metadata": {},
   "source": [
    "### Contruct the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf598fa-9c78-484e-8ce9-0879b9bcf792",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_pattern = '(\\w*):\\s*\\*\\*\\s*\\$(\\d*\\-*\\d*)\\*\\*'\n",
    "title_pattern = '\\[(?:GB|Pre-order)\\]\\s*(.*)\\s*//' #Trying not to lower case to preserve some kb title that has uppercase\n",
    "date_pattern = '//(.*)-(.*)'\n",
    "vendor_pattern = '(\\w*:\\s*)\\[(\\w*)\\]'\n",
    "#ship_date_pattern = '(?:est\\.\\s*shipping\\s*date|est.\\s*fulfillment\\s*date):\\s*\\*\\*(.*?)\\*\\*---'\n",
    "ship_date_pattern = '(?:.*?):\\s*\\*\\*(.*?)\\*\\*---'\n",
    "#ship_date_pattern = '(?:ests*shipping\\s*date|est.\\s*fulfillment\\s*date):\\s*\\*\\*(.*?)\\*\\*---'\n",
    "\n",
    "type_list = []\n",
    "price_list = []\n",
    "title_list = []\n",
    "start_list = []\n",
    "end_list = []\n",
    "country_list = []\n",
    "vendor_list = []\n",
    "ship_date_list = []\n",
    "\n",
    "for scrp in scraped_data:\n",
    "  price_tup = re.findall(price_pattern, scrp['sticky_comment'].replace('\\n', ''))\n",
    "  try:\n",
    "    title = re.findall(title_pattern, scrp['title'].replace('\\n', ''))[0] #Title should match only 1 string  \n",
    "  except:\n",
    "    title = scrp['title'].replace('[GB]', '').strip()\n",
    "  try:\n",
    "    ship_date = re.findall(ship_date_pattern, scrp['sticky_comment'].replace('\\n', '').lower())[0]\n",
    "  except:\n",
    "    ship_date = None\n",
    "      \n",
    "  # first index is for tuple, second index is for the starting/ending date\n",
    "  try:\n",
    "    start_date = re.findall(date_pattern, scrp['title'].replace('\\n', ''))[0][0].strip().lower()\n",
    "    end_date = re.findall(date_pattern, scrp['title'].replace('\\n', ''))[0][1].strip().lower()\n",
    "    start_date, end_date = process_date(start_date, end_date)\n",
    "  except:\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "  \n",
    "  vendor_tup = re.findall(vendor_pattern, scrp['sticky_comment'].replace('\\n', ''))\n",
    "  \n",
    "  #print(start_date, end_date)\n",
    "    \n",
    "  for p_tup in price_tup: \n",
    "    for v_tup in vendor_tup:      \n",
    "      \n",
    "      type_list.append(p_tup[0])\n",
    "      price_list.append(p_tup[1])\n",
    "      \n",
    "      country_list.append(v_tup[0])\n",
    "      vendor_list.append(v_tup[1])\n",
    "\n",
    "      # These 4 need to be duplicated across price/country\n",
    "      title_list.append(title)\n",
    "      start_list.append(start_date)\n",
    "      end_list.append(end_date)\n",
    "      ship_date_list.append(ship_date)\n",
    "\n",
    "df = pd.DataFrame({'title': title_list, 'type': type_list, 'price': price_list, 'start_date': start_list, 'end_date':end_list,\n",
    "                   'country': country_list, 'vendor': vendor_list, 'ship_date': ship_date_list\n",
    "                  })\n",
    "df['price'] = df['price'].apply(lambda x: process_price(x, mode='mid'))\n",
    "#df[df['ship_date'].isna()]['title'].drop_duplicates()\n",
    "#df.count()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e36341-2b92-4eb0-926d-93b7084dff73",
   "metadata": {},
   "source": [
    "### Try to Extract the type (Keyboard vs Keycap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51522932-1a5a-4152-89f2-444897ca31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need heuristic to separate (unless use some model to separate pictures)\n",
    "# keycap title may contains GMK, ePBT, MW, Domikey, DCS, SA\n",
    "# keycap type may include Alphas, Numpad, Spacebars, keycap\n",
    "\n",
    "# Let the rest falls down to keybaord, the hard part would be to differentiate keybard and switch\n",
    "# Switch may be look from linear/tactile in the description or something\n",
    "\n",
    "#df[df['price']<15]\n",
    "#df[(df['type'].str.lower().str.contains('switch')) | (df['title'].str.lower().str.contains('switch'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd4bb1a-88c2-4d35-8a9d-c8d760f54784",
   "metadata": {},
   "source": [
    "### Distribution of price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8d692-0d45-4816-bcc5-c0ca989d023a",
   "metadata": {},
   "source": [
    "### Distribution of Keyboard Type "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adf390-4547-446b-9fa8-44f106953d42",
   "metadata": {},
   "source": [
    "### Distribution of the Studio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f077b324-1425-4789-ac8e-ca00bdc5594f",
   "metadata": {},
   "source": [
    "### Visualization of number of active group buy in a Year (maybe a stack chart of avaialble group buys/ price need to buy everything, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b065a3-6002-4858-9cab-e6ab4625f320",
   "metadata": {},
   "source": [
    "### Time from Group Buy to Release (as per the initial announcement data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d2612-e8b0-449b-98de-10b2bf509ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
